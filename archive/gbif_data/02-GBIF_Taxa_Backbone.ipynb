{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author.      : Aditya Jain\n",
    "Date Started : 1st April, 2021\n",
    "About        : This script fetches unique key for moth species from GBIF database\n",
    "               and builds a global list of moth species with unique IDs\n",
    "'''\n",
    "\n",
    "!pip install pygbif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qsYGHMo34CWR"
   },
   "outputs": [],
   "source": [
    "from pygbif import occurrences as occ\n",
    "from pygbif import species as species_api\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "\n",
    "DATA_DIR   = \"/content/drive/My Drive/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zPTloCcM5eX-"
   },
   "outputs": [],
   "source": [
    "def get_gbif_key_backbone(name, place):\n",
    "  '''\n",
    "  given a species name, this function returns the unique gbif key and other\n",
    "  attributes using backbone API\n",
    "  '''\n",
    "  # default values\n",
    "  taxon_key     = ['NA']\n",
    "  confidence    = ['']\n",
    "  gbif_species  = ['NA']     # the name returned on search, can be different from the search\n",
    "  status        = ['NA']\n",
    "  match_type    = ['NONE']\n",
    "  place         = [place]\n",
    "\n",
    "  data = species_api.name_backbone(name=name, strict=True, rank='species')\n",
    "\n",
    "  if data['matchType'] == 'NONE':\n",
    "    confidence    = [data['confidence']]\n",
    "  else:\n",
    "    taxon_key     = [data['usageKey']]\n",
    "    confidence    = [data['confidence']]\n",
    "    gbif_species  = [data['species']]\n",
    "    status        = [data['status']]\n",
    "    match_type    = [data['matchType']]\n",
    "  \n",
    "  df = pd.DataFrame(list(zip(taxon_key, confidence, gbif_species, status, \n",
    "                             match_type, place)),\n",
    "                    columns =['taxon Key', 'confidence', 'GBIF species name', \n",
    "                              'status', 'match type', 'source'])\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9O1ZizdQ5J_D"
   },
   "source": [
    "### **Pohl list**: Getting unique GBIF id's for Quebec species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Gl_DilE4zDz",
    "outputId": "5b1064b0-378b-42f9-9dbf-975f231696ab"
   },
   "outputs": [],
   "source": [
    "quebec_species = 'listB_Quebec_Pohl2018.csv'\n",
    "file           = DATA_DIR + quebec_species\n",
    "quebec_data    = pd.read_csv(file, index_col=False)\n",
    "species        = list(quebec_data['GBIF species name'])\n",
    "\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knQct-2nwdKp"
   },
   "source": [
    "**Need to run the below only once to get the keys!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1ileUht1MFO"
   },
   "outputs": [],
   "source": [
    "data_final = pd.DataFrame(columns =['taxon Key', 'confidence', 'GBIF species name', \n",
    "                              'status', 'match type', 'source'])\n",
    "# data_final = pd.read_csv(DATA_DIR + 'key_list.csv')\n",
    "\n",
    "for name in species:\n",
    "  data = get_gbif_key_backbone(name, 'Quebec_Pohl2018')\n",
    "  print(name)\n",
    "  data_final = data_final.append(data, ignore_index = True)\n",
    "  data_final.to_csv(DATA_DIR + 'key_list.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXU5t2LOyWQh"
   },
   "source": [
    "Run the below to add keys in original file and save the new list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tAl5yiiWs2Q",
    "outputId": "31fb03e5-8d1c-4f3e-e33c-32d762015b56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SP NO.       superfamily  ... match type           source\n",
      "0      010001  Micropterigoidea  ...      EXACT  Quebec_Pohl2018\n",
      "1      070001    Eriocranioidea  ...      EXACT  Quebec_Pohl2018\n",
      "2      070003    Eriocranioidea  ...      EXACT  Quebec_Pohl2018\n",
      "3      070004    Eriocranioidea  ...      EXACT  Quebec_Pohl2018\n",
      "4     070008P    Eriocranioidea  ...      EXACT  Quebec_Pohl2018\n",
      "...       ...               ...  ...        ...              ...\n",
      "3145   933680        Noctuoidea  ...      EXACT  Quebec_Pohl2018\n",
      "3146   933682        Noctuoidea  ...      EXACT  Quebec_Pohl2018\n",
      "3147   933683        Noctuoidea  ...      EXACT  Quebec_Pohl2018\n",
      "3148   933685        Noctuoidea  ...      EXACT  Quebec_Pohl2018\n",
      "3149   933688        Noctuoidea  ...      EXACT  Quebec_Pohl2018\n",
      "\n",
      "[3150 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "file        = 'Pohl2018_Keylist.csv'\n",
    "key_data    = pd.read_csv(DATA_DIR + file)\n",
    "\n",
    "quebec_data = quebec_data.iloc[:, 0:8]\n",
    "\n",
    "final_pohl_list = pd.concat([quebec_data, key_data], axis=1)\n",
    "final_pohl_list.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(final_pohl_list)\n",
    "final_pohl_list.to_csv(DATA_DIR + 'listB_Quebec_Pohl2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alc9SqMFBg5C"
   },
   "source": [
    "ONLY If the missing cells does not have NA, the below code is run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LDXjL5Zm_wcO"
   },
   "outputs": [],
   "source": [
    "quebec_data.fillna(\"-1\", inplace = True)\n",
    "quebec_data = quebec_data.astype({\"taxon Key\": int})\n",
    "quebec_data.to_csv(DATA_DIR + 'listB_Quebec_Pohl2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-H9-jSP_z11-"
   },
   "source": [
    "### **Vermont list**: Getting unique GBIF id's for Vermont species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTwyxW06tr3v",
    "outputId": "c2c892e6-91f1-4525-ca4b-3d5f93cbaff8"
   },
   "outputs": [],
   "source": [
    "vermont_species = 'listC_Vermont_29March2021.csv'\n",
    "file            = DATA_DIR + vermont_species\n",
    "vermont_data    = pd.read_csv(file)\n",
    "species         = list(vermont_data['scientificName'])\n",
    "\n",
    "print(species)\n",
    "print(len(species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VfhjOko0wQy"
   },
   "outputs": [],
   "source": [
    "data_final = pd.DataFrame(columns =['taxon Key', 'confidence', 'GBIF species name', \n",
    "                              'status', 'match type', 'source'])\n",
    "# data_final = pd.read_csv(DATA_DIR + 'Vermont2021_Keylist.csv')\n",
    "\n",
    "for name in species:\n",
    "  print(name)\n",
    "  data = get_gbif_key_backbone(name, 'Vermont_29March2021')\n",
    "  data_final = data_final.append(data, ignore_index = True)\n",
    "  data_final.to_csv(DATA_DIR + 'key_list.csv', index=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPDPtGfRXxip"
   },
   "source": [
    "Appending key list to original vermont file and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCwe0ZLxXU7r",
    "outputId": "1166b273-cd13-4df5-9878-d942125b880f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hodges_No      P3no  group  ...    status match type               source\n",
      "0           1.0   10001.0  micro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "1           3.0   70001.0  micro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "2           5.0   70003.0  micro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "3          31.0  110011.0  micro  ...  DOUBTFUL      EXACT  Vermont_29March2021\n",
      "4          18.0  110016.0  micro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "...         ...       ...    ...  ...       ...        ...                  ...\n",
      "1935    11043.0  933685.0  macro  ...   SYNONYM      EXACT  Vermont_29March2021\n",
      "1936    11045.0  933688.0  macro  ...   SYNONYM      EXACT  Vermont_29March2021\n",
      "1937    10658.0   34151.0  macro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "1938     3412.2  621291.2  micro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "1939     6405.0  910822.0  macro  ...  ACCEPTED      EXACT  Vermont_29March2021\n",
      "\n",
      "[1940 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "file        = 'Vermont2021_Keylist.csv'\n",
    "key_data    = pd.read_csv(DATA_DIR + file)\n",
    "\n",
    "vermont_data = vermont_data.iloc[:, 0:10]\n",
    "\n",
    "final_vermont_list = pd.concat([vermont_data, key_data], axis=1)\n",
    "# final_vermont_list.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(final_vermont_list)\n",
    "final_vermont_list.to_csv(DATA_DIR + 'listC_Vermont_29March2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "R0AQUSIsLcua"
   },
   "outputs": [],
   "source": [
    "vermont_data.fillna(\"-1\", inplace = True)\n",
    "vermont_data = vermont_data.astype({\"taxon Key\": int})\n",
    "vermont_data.to_csv(DATA_DIR + 'listC_Vermont_29March2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCQDOxpr1wd0"
   },
   "source": [
    "## Making global file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "an2XnLPwrGIO"
   },
   "outputs": [],
   "source": [
    "global_columns = ['taxon key', 'superfamily', 'family', \n",
    "                  'subfamily', 'genus', 'name', 'scientific name',\n",
    "                  'gbif scientific name', 'confidence', 'status',\n",
    "                  'match type', 'source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LQQijMNVM5I"
   },
   "source": [
    "#### First fetching data from Quebec list to build global file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3EeTT81KU43T"
   },
   "outputs": [],
   "source": [
    "quebec_species = 'listB_Quebec_Pohl2018.csv'\n",
    "file           = DATA_DIR + quebec_species\n",
    "quebec_data    = pd.read_csv(file, index_col=False)\n",
    "\n",
    "# fetch relevant data from Pohl list\n",
    "global_list    = quebec_data[['taxon Key', 'superfamily', \n",
    "                              'family', 'subfamily', 'val genus', 'name',\n",
    "                              'Scientific Name', 'GBIF species name', \n",
    "                              'confidence', 'status', 'match type', 'source']]\n",
    "\n",
    "global_list.columns = global_columns\n",
    "global_list.to_csv(DATA_DIR + 'listX_GlobalMothList_7April2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udKNLb0wYuvJ"
   },
   "source": [
    "#### Adding Vermont data to global list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pER2j-QLqYOx",
    "outputId": "759313af-e1fe-4441-d24c-fdd3aa2b72a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      taxon key       superfamily  ... match type               source\n",
      "0       1939759  Micropterigoidea  ...      EXACT  Vermont_29March2021\n",
      "1       1731862    Eriocranioidea  ...      EXACT  Vermont_29March2021\n",
      "2       1731826    Eriocranioidea  ...      EXACT  Vermont_29March2021\n",
      "3      10067382       Hepialoidea  ...      EXACT  Vermont_29March2021\n",
      "4       1829029       Hepialoidea  ...      EXACT  Vermont_29March2021\n",
      "...         ...               ...  ...        ...                  ...\n",
      "1935    4301258        Noctuoidea  ...      EXACT  Vermont_29March2021\n",
      "1936    4301263        Noctuoidea  ...      EXACT  Vermont_29March2021\n",
      "1937    1771249        Noctuoidea  ...      EXACT  Vermont_29March2021\n",
      "1938    1738829      Tortricoidea  ...      EXACT  Vermont_29March2021\n",
      "1939    9453490      Geometroidea  ...      EXACT  Vermont_29March2021\n",
      "\n",
      "[1940 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "global_species  = 'listX_GlobalMothList_7April2021.csv'\n",
    "file            = DATA_DIR + global_species\n",
    "global_data     = pd.read_csv(file)\n",
    "\n",
    "vermont_species = 'listC_Vermont_29March2021.csv'\n",
    "file            = DATA_DIR + vermont_species\n",
    "vermont_data    = pd.read_csv(file)\n",
    "vermont_data    = vermont_data[['taxon Key', 'superfamily',\n",
    "                                'family', 'subfamily', 'genus',\n",
    "                                'specificEpithet', 'scientificName',\n",
    "                                'GBIF species name','confidence', 'status', \n",
    "                                'match type', 'source']]\n",
    "\n",
    "vermont_data.columns = global_columns\n",
    "print(vermont_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AI_j46MRsZkg"
   },
   "outputs": [],
   "source": [
    "for indx in vermont_data.index:\n",
    "  taxa_key  = vermont_data['taxon key'][indx]\n",
    "  taxa_name = vermont_data['scientific name'][indx]\n",
    "  if taxa_key!=-1 and taxa_key in list(global_data['taxon key']):\n",
    "    row_ind                            = global_data[global_data['taxon key']==taxa_key].index.values[0]\n",
    "    temp_val                           = global_data.loc[row_ind, 'source']\n",
    "    global_data.loc[row_ind, 'source'] = temp_val + ' ' + vermont_data['source'][indx]\n",
    "  \n",
    "  elif taxa_key==-1 and taxa_name in list(global_data['scientific name']):\n",
    "    row_ind                            = global_data[global_data['scientific name']==taxa_name].index.values[0]\n",
    "    temp_val                           = global_data.loc[row_ind, 'source']\n",
    "    global_data.loc[row_ind, 'source'] = temp_val + ' ' + vermont_data['source'][indx]\n",
    "  \n",
    "  else:\n",
    "    global_data = global_data.append(vermont_data.loc[indx, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7hKCCDpG-0kZ"
   },
   "outputs": [],
   "source": [
    "global_data.to_csv(DATA_DIR + 'listX_GlobalMothList_7April2021.csv', index=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSYEm90cEFWr"
   },
   "source": [
    "## Count no. of not-found entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wvs2TTDx0CxA",
    "outputId": "17dd1fd9-6a35-4520-dc75-be5c3988cf38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "global_species  = 'listX_GlobalMothList_7April2021.csv'\n",
    "file            = DATA_DIR + global_species\n",
    "global_data     = pd.read_csv(file) \n",
    "count           = 0\n",
    "no_search       = []\n",
    "\n",
    "for indx in global_data.index:\n",
    "  if global_data['taxon key'][indx] == -1:\n",
    "    count += 1\n",
    "    no_search.append(global_data['scientific name'][indx])\n",
    "\n",
    "print(count)\n",
    "no_search = pd.DataFrame(no_search)\n",
    "no_search.to_csv(DATA_DIR + 'not-found_7April2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5D4v5tyZoTW"
   },
   "source": [
    "## Miscellaneous - Not to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cmH8YzcIo22q",
    "outputId": "f33cb6ed-3242-4a88-b7cd-570ae3a1e578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"usageKey\": 9538415,\n",
      "   \"scientificName\": \"Stigmella cerea (Braun, 1917) Newton et al., 1982\",\n",
      "   \"canonicalName\": \"Stigmella cerea\",\n",
      "   \"rank\": \"SPECIES\",\n",
      "   \"status\": \"ACCEPTED\",\n",
      "   \"confidence\": 99,\n",
      "   \"matchType\": \"EXACT\",\n",
      "   \"kingdom\": \"Animalia\",\n",
      "   \"phylum\": \"Arthropoda\",\n",
      "   \"order\": \"Lepidoptera\",\n",
      "   \"family\": \"Nepticulidae\",\n",
      "   \"genus\": \"Stigmella\",\n",
      "   \"species\": \"Stigmella cerea\",\n",
      "   \"kingdomKey\": 1,\n",
      "   \"phylumKey\": 54,\n",
      "   \"classKey\": 216,\n",
      "   \"orderKey\": 797,\n",
      "   \"familyKey\": 7014,\n",
      "   \"genusKey\": 1735652,\n",
      "   \"speciesKey\": 9538415,\n",
      "   \"synonym\": false,\n",
      "   \"class\": \"Insecta\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54MzSissW9jD"
   },
   "outputs": [],
   "source": [
    "file     = 'Pohl2018_Keylist.csv'\n",
    "key_data = pd.read_csv(DATA_DIR + file)\n",
    "\n",
    "# fetch relevant data from Pohl list\n",
    "relv_data    = quebec_data[['superfamily', 'family', 'subfamily', 'val genus', 'name']]\n",
    "species_n    = quebec_data['val genus'] + ' ' + quebec_data['name']\n",
    "\n",
    "final_data   = pd.concat([key_data[['Species Key', 'Taxon Key']], \n",
    "                          relv_data, species_n, \n",
    "                          key_data[['GBIF Species Name', 'Source']],\n",
    "                          quebec_data['SP NO.']],                         \n",
    "                          axis=1)\n",
    "\n",
    "global_data  = pd.DataFrame(final_data, columns = global_columns)\n",
    "global_data.to_csv(DATA_DIR + 'listX_GlobalMothList_2April2021.csv') "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GBIF_Taxa_Backbone.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (milamoth)",
   "language": "python",
   "name": "milamoth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
