{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qE95z02t2vVZ",
    "outputId": "25e9b101-79b3-4548-96e8-81aecb260558"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor.      : Aditya Jain\\nDate Started : 28th June, 2021\\nAbout        : This script fetches unique key for non-moth taxas\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Author.      : Aditya Jain\n",
    "Date Started : 28th June, 2021\n",
    "About        : This script fetches unique key for non-moth taxas\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qsYGHMo34CWR"
   },
   "outputs": [],
   "source": [
    "from pygbif import occurrences as occ\n",
    "from pygbif import species as species_api\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "import math  \n",
    "\n",
    "DATA_DIR       = '/home/mila/a/aditya.jain/mothAI/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zPTloCcM5eX-"
   },
   "outputs": [],
   "source": [
    "def get_gbif_key_backbone(name):\n",
    "    '''\n",
    "    given a taxa name, this function returns the unique gbif key and other\n",
    "    attributes using backbone API\n",
    "    '''\n",
    "    # default values\n",
    "    search_name   = [name]\n",
    "    taxon_key     = ['NA']\n",
    "    confidence    = ['']\n",
    "    gbif_name     = ['NA']     # the name returned on search, can be different from the search\n",
    "    status        = ['NA']\n",
    "    rank          = ['NA']\n",
    "    match_type    = ['NONE']\n",
    "    count_down    = [30000]\n",
    "\n",
    "    data = species_api.name_backbone(name=name, strict=True)\n",
    "\n",
    "    if data['matchType'] == 'NONE':\n",
    "        confidence    = [data['confidence']]\n",
    "    else:\n",
    "        taxon_key     = [data['usageKey']]\n",
    "        confidence    = [data['confidence']]\n",
    "        gbif_name     = [data['scientificName']]\n",
    "        status        = [data['status']]\n",
    "        rank          = [data['rank']]\n",
    "        match_type    = [data['matchType']]\n",
    "  \n",
    "    df = pd.DataFrame(list(zip(taxon_key, confidence, search_name, gbif_name, rank, status, \n",
    "                             match_type, count_down)),\n",
    "                    columns =['Taxon Key', 'Confidence', 'Search Name','GBIF Taxa Name', \n",
    "                              'Rank', 'Status', 'Match Type', 'Count Download'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonmoth_list = ['Trichoptera', 'Formicidae', 'Ichneumonidae', 'Diptera', \n",
    "                'Orthoptera', 'Hemiptera', 'Pholcidae', 'Araneae', 'Opiliones']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.DataFrame(columns =['Taxon Key', 'Confidence', 'Search Name','GBIF Taxa Name', \n",
    "                              'Rank', 'Status', 'Match Type', 'Count Download'])\n",
    "\n",
    "for name in nonmoth_list:\n",
    "    data = get_gbif_key_backbone(name)\n",
    "    data_final = data_final.append(data, ignore_index = True)\n",
    "    data_final.to_csv(DATA_DIR + 'NonMothList_30June2021.csv', index = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1003,99,Trichoptera,Trichoptera,ORDER,ACCEPTED,EXACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usageKey': 907, 'scientificName': 'Opiliones', 'canonicalName': 'Opiliones', 'rank': 'ORDER', 'status': 'ACCEPTED', 'confidence': 95, 'matchType': 'EXACT', 'kingdom': 'Animalia', 'phylum': 'Arthropoda', 'order': 'Opiliones', 'kingdomKey': 1, 'phylumKey': 54, 'orderKey': 907, 'synonym': False}\n"
     ]
    }
   ],
   "source": [
    "data = species_api.name_backbone(name='Chelicerata', verbose=True)\n",
    "data = species_api.name_backbone(name='Opiliones', strict=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR       = \"/home/mila/a/aditya.jain/mothAI/\"\n",
    "WRITE_DIR      = \"/home/mila/a/aditya.jain/testnm/nonmothdata/\"\n",
    "INat_KEY       = \"50c9509d-22c7-4a22-a47d-8c48425ef4a7\"   # iNat key to fetch data from GBIF\n",
    "LIMIT_DOWN     = 300                                      # GBIF API parameter for max results per page\n",
    "MAX_DATA_SP    = 5                                        # max. no of images to download for a species\n",
    "MAX_SEARCHES   = 40000                                    # maximum no. of points to iterate\n",
    "\n",
    "nonmoth_taxa   = 'NonMothList_30June2021.csv'\n",
    "file           = DATA_DIR + nonmoth_taxa\n",
    "nonmoth_data   = pd.read_csv(file)\n",
    "\n",
    "def inat_metadata_gbif(data):\n",
    "    '''\n",
    "    this function returns the relevant gbif metadata for an iNat observation\n",
    "    '''\n",
    "    fields    = ['decimalLatitude', 'decimalLongitude', 'phylum',\n",
    "            'order', 'family', 'genus', 'species', 'acceptedScientificName',\n",
    "            'year', 'month', 'day',\n",
    "            'datasetName', 'taxonID', 'acceptedTaxonKey']\n",
    "\n",
    "    meta_data = {}\n",
    "\n",
    "    for field in fields:\n",
    "        if field in data.keys():\n",
    "            meta_data[field] = data[field]\n",
    "        else:\n",
    "            meta_data[field] = ''\n",
    "\n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxon_key          = list(nonmoth_data['Taxon Key'])              # list of taxon keys\n",
    "taxon_name         = list(nonmoth_data['Search Name'])        # list of species name that is searched\n",
    "gbif_taxon_name    = list(nonmoth_data['GBIF Taxa Name'])   # list of species name returned by gbif [can be different from above or -1]\n",
    "\n",
    "\n",
    "### this snippet is run ONLY is training is resuming from some point ####\n",
    "# start              = 111\n",
    "# end                = ''\n",
    "# taxon_key          = taxon_key[start:]\n",
    "# species_name       = species_name[start:]\n",
    "# gbif_taxon_name  = gbif_species_name[start:]\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading for:  Trichoptera\n",
      "Time taken to download data for  Trichoptera  is -  3 sec for  5  images\n",
      "Downloading for:  Formicidae\n",
      "Time taken to download data for  Formicidae  is -  3 sec for  5  images\n",
      "Downloading for:  Ichneumonidae\n",
      "Time taken to download data for  Ichneumonidae  is -  5 sec for  5  images\n",
      "Downloading for:  Diptera\n",
      "Time taken to download data for  Diptera  is -  3 sec for  5  images\n",
      "Downloading for:  Orthoptera\n",
      "Time taken to download data for  Orthoptera  is -  3 sec for  5  images\n",
      "Downloading for:  Hemiptera\n",
      "Time taken to download data for  Hemiptera  is -  5 sec for  5  images\n",
      "Downloading for:  Pholcidae\n",
      "Time taken to download data for  Pholcidae  is -  3 sec for  5  images\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(taxon_key)):\n",
    "    print('Downloading for: ', gbif_taxon_name[i])\n",
    "    begin       = time.time()\n",
    "    data        = occ.search(taxonKey = taxon_key[i], mediatype='StillImage', limit=1)\n",
    "    total_count = data['count'] \n",
    "    \n",
    "    if total_count==0:            # no data for the species on iNat\n",
    "        print('No image record!')   \n",
    "    else:\n",
    "        image_count = 0                                   # images downloaded for every species\n",
    "        max_count   = min(total_count, MAX_DATA_SP)\n",
    "        total_pag   = math.ceil(MAX_SEARCHES/LIMIT_DOWN)  # total pages to be fetched with max 300 entries each\n",
    "        offset      = 0  \n",
    "        m_data      = {}                                 # dictionary variable to store metadata\n",
    "        \n",
    "        write_loc   = WRITE_DIR + gbif_taxon_name[i] \n",
    "        try:    \n",
    "            os.makedirs(write_loc)                     # creating hierarchical structure for image storage \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        for j in range(total_pag):\n",
    "            data       = occ.search(taxonKey = taxon_key[i], mediatype='StillImage', \n",
    "                               limit=LIMIT_DOWN, offset=offset)\n",
    "            tot_points = len(data['results'])\n",
    "            \n",
    "            for k in range(tot_points):                \n",
    "                if data['results'][k]['media']: \n",
    "                    gbifid   = data['results'][k]['gbifID']\n",
    "                \n",
    "                    if 'identifier' in data['results'][k]['media'][0].keys():\n",
    "                        image_url   = data['results'][k]['media'][0]['identifier']            \n",
    "                        try:\n",
    "                            urllib.request.urlretrieve(image_url, write_loc + '/' + gbifid + '.jpg')\n",
    "                            image_count += 1              \n",
    "                            meta_data      = inat_metadata_gbif(data['results'][k])   # fetching metadata\n",
    "                            m_data[gbifid] = meta_data                 \n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                if image_count >= max_count:\n",
    "                        break\n",
    "                \n",
    "            offset += LIMIT_DOWN\n",
    "            if image_count >= max_count:\n",
    "                break\n",
    "                \n",
    "        with open(write_loc + '/' + 'metadata.txt', 'w') as outfile:\n",
    "                json.dump(m_data, outfile)\n",
    "                \n",
    "        end = time.time()\n",
    "        print('Time taken to download data for ', gbif_taxon_name[i], ' is - ', \n",
    "        round(end-begin), 'sec for ', image_count, ' images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GBIF_Taxa_Backbone.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (milamoth)",
   "language": "python",
   "name": "milamoth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
