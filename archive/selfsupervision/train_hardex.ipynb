{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor        : Aditya Jain\\nDate started  : 10th January, 2022\\nAbout         : This script fine tunes the model with hard examples\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Author        : Aditya Jain\n",
    "Date started  : 10th January, 2022\n",
    "About         : This script fine tunes the model with hard examples\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/adityajain07/selfsupervision/fb6c0eb26030426486ed72efe2def194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"epeaAhyRcHSkn92H4kusmbX8k\",\n",
    "    project_name=\"selfsupervision\",\n",
    "    workspace=\"adityajain07\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms, utils\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from data.imagenetvaldataset import ImagenetValDataset\n",
    "from data.hardexdataset import HardExDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading pre-trained ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model  = models.resnet50(pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edits to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_root_dir       = '/network/datasets/imagenet.var/imagenet_torchvision/val/'\n",
    "val_label_list     = '/home/mila/a/aditya.jain/mothAI/selfsupervision/data/validation_imagenet_labels.csv'\n",
    "val_convert_list   = '/home/mila/a/aditya.jain/mothAI/selfsupervision/data/imagenet_modified_labels.csv'\n",
    "\n",
    "hardex_data_dir    = '/home/mila/a/aditya.jain/scratch/selfsupervise_data/hard_examples/'\n",
    "hardex_label_list  = '/home/mila/a/aditya.jain/mothAI/selfsupervision/data/hard_examples_data.csv'\n",
    "\n",
    "image_resize       = 224\n",
    "batch_size         = 32\n",
    "\n",
    "DTSTR              = datetime.datetime.now()\n",
    "DTSTR              = DTSTR.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "mod_save_path      = '/home/mila/a/aditya.jain/logs/'\n",
    "mod_name           = 'selfsupervisemodel'\n",
    "mod_ver            = 'v1'\n",
    "save_path          = mod_save_path + mod_name + '_' + mod_ver  + '_' + DTSTR + '.pt'\n",
    "early_stop         = 4\n",
    "epochs             = 30\n",
    "\n",
    "transformer        = transforms.Compose([\n",
    "                        transforms.Resize((image_resize, image_resize)),              # resize the image to 224x224 \n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data          = ImagenetValDataset(val_root_dir, val_label_list, val_convert_list, transformer)\n",
    "val_dataloader    = DataLoader(val_data,batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(predictions, labels):\n",
    "    '''\n",
    "    calculates top1, top5 and top10 correct predictions in a batch\n",
    "    '''\n",
    "    top1         = 0\n",
    "    top5         = 0\n",
    "    top10        = 0\n",
    "    \n",
    "    _, pr_indices1  = torch.topk(predictions, 1)\n",
    "    _, pr_indices5  = torch.topk(predictions, 5)\n",
    "    _, pr_indices10 = torch.topk(predictions, 10)\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] in pr_indices1[i]:\n",
    "            top1 += 1\n",
    "        \n",
    "        if labels[i] in pr_indices5[i]:\n",
    "            top5 += 1\n",
    "            \n",
    "        if labels[i] in pr_indices10[i]:\n",
    "            top10 += 1\n",
    "            \n",
    "    return top1, top5, top10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_correct  = 0\n",
    "top5_correct  = 0\n",
    "top10_correct = 0\n",
    "total         = 0\n",
    "\n",
    "model.eval()\n",
    "for image_batch, label_batch in val_dataloader:\n",
    "    \n",
    "    image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "    predictions              = model(image_batch)    \n",
    "    top1, top5, top10        = batch_accuracy(predictions, label_batch)\n",
    "   \n",
    "    top1_correct    += top1\n",
    "    top5_correct    += top5\n",
    "    top10_correct   += top10\n",
    "    total           += len(label_batch)\n",
    "    \n",
    "pretrain_accuracy                   = {}\n",
    "pretrain_accuracy['top1_pretrain_val']  = top1_correct/total*100\n",
    "pretrain_accuracy['top5_pretrain_val']  = top5_correct/total*100\n",
    "pretrain_accuracy['top10_pretrain_val'] = top10_correct/total*100\n",
    "\n",
    "experiment.log_metrics(pretrain_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning using hard examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardex_data        = HardExDataset(hardex_data_dir, hardex_label_list, transformer)\n",
    "hardex_dataloader  = DataLoader(hardex_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_val_loss  = 10000000\n",
    "lowest_val_loss = start_val_loss\n",
    "early_stp_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    val_loss   = 0\n",
    "    s_time     = time.time()\n",
    "    \n",
    "    # model fine-tuning\n",
    "    model.train()\n",
    "    for image_batch, label_batch in hardex_dataloader:\n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch              = label_batch.squeeze_() \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs   = model(image_batch)        \n",
    "        t_loss    = loss_func(outputs, label_batch)\n",
    "        t_loss.backward()\n",
    "        optimizer.step()        \n",
    "        train_loss += t_loss.item()\n",
    "        \n",
    "    experiment.log_metric(\"loss_train\", train_loss, epoch=epoch)\n",
    "    \n",
    "    # model evaluation\n",
    "    top1_correct  = 0\n",
    "    top5_correct  = 0\n",
    "    top10_correct = 0\n",
    "    total         = 0\n",
    "\n",
    "    model.eval()\n",
    "    for image_batch, label_batch in val_dataloader:    \n",
    "        image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "        label_batch              = label_batch.squeeze_() \n",
    "        predictions              = model(image_batch)\n",
    "        \n",
    "        v_loss    = loss_func(predictions, label_batch)\n",
    "        val_loss += v_loss.item()\n",
    "        \n",
    "        top1, top5, top10  = batch_accuracy(predictions, label_batch)   \n",
    "        top1_correct      += top1\n",
    "        top5_correct      += top5\n",
    "        top10_correct     += top10\n",
    "        total             += len(label_batch)\n",
    "    \n",
    "    experiment.log_metric(\"loss_val\", val_loss, epoch=epoch)\n",
    "    experiment.log_metric('top1_tuned_val', top1_correct/total*100, epoch=epoch)\n",
    "    experiment.log_metric('top5_tuned_val', top5_correct/total*100, epoch=epoch)\n",
    "    experiment.log_metric('top10_tuned_val', top10_correct/total*100, epoch=epoch)\n",
    "    \n",
    "    e_time = (time.time()-s_time)/60      \n",
    "    experiment.log_metric(\"time_per_epoch\", e_time, epoch=epoch)\n",
    "    \n",
    "    if val_loss<lowest_val_loss:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss':val_loss}, \n",
    "            save_path)               \n",
    "        lowest_val_loss = val_loss\n",
    "        early_stp_count = 0\n",
    "    else:\n",
    "        early_stp_count += 1 \n",
    "        \n",
    "    if early_stp_count>=early_stop:\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate class-wise accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only when running separately, otherwise the current model is used\n",
    "PATH       = '/home/mila/a/aditya.jain/logs/selfsupervisemodel_v1_2022-01-30-23-00.pt'\n",
    "checkpoint = torch.load(PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# changing batch size\n",
    "batch_size        = 1 \n",
    "val_data          = ImagenetValDataset(val_root_dir, val_label_list, val_convert_list, transformer)\n",
    "val_dataloader    = DataLoader(val_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc         = {}  # storing the class accuracy data\n",
    "\n",
    "data_loc          = '/home/mila/a/aditya.jain/scratch/selfsupervise_data/hard_examples/'\n",
    "hard_classes      = os.listdir(data_loc)\n",
    "\n",
    "with open(\"/home/mila/a/aditya.jain/mothAI/selfsupervision/data/imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for image_batch, label_batch in val_dataloader:\n",
    "    \n",
    "    image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n",
    "    prediction               = model(image_batch)    \n",
    "    _, index                 = torch.topk(prediction, 1)\n",
    "    \n",
    "    corr_label   = label_batch.cpu().numpy()[0][0]    # integer label of the true class\n",
    "    corr_class_n = categories[corr_label]             # name of the class\n",
    "    pred_label   = index.cpu().numpy()[0][0]          # integer label of the predicted class\n",
    "    \n",
    "    if corr_class_n not in class_acc.keys():\n",
    "        class_acc[corr_class_n] = {}\n",
    "        class_acc[corr_class_n]['total_correct'] = 0\n",
    "        class_acc[corr_class_n]['total_samples'] = 0\n",
    "        \n",
    "    if corr_label==pred_label:\n",
    "        class_acc[corr_class_n]['total_correct'] += 1\n",
    "        class_acc[corr_class_n]['total_samples'] += 1\n",
    "    else:\n",
    "        class_acc[corr_class_n]['total_samples'] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_ex_data    = []     # classes for which we have hard examples\n",
    "nonhard_ex_data = []     # classes for which we don't have hard examples\n",
    "\n",
    "for key in class_acc.keys():\n",
    "    if key in hard_classes:\n",
    "        hard_ex_data.append([categories.index(key), key, round((class_acc[key]['total_correct']/class_acc[key]['total_samples'])*100,2)])\n",
    "    else:\n",
    "        nonhard_ex_data.append([categories.index(key), key, round((class_acc[key]['total_correct']/class_acc[key]['total_samples'])*100,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_acc_data  = pd.read_csv(ILSVRC_LABEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth)",
   "language": "python",
   "name": "milamoth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
