{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author       : Aditya Jain\n",
    "Date Started : May 21, 2022\n",
    "About        : This file does DL-based localization and classification on raw images and saves annotation information\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision.models as torchmodels\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-defined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir     = '/home/mila/a/aditya.jain/scratch/TrapData_QuebecVermont_2022/Vermont/'\n",
    "image_folder = '2022_05_13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path  = data_dir + image_folder + '/'\n",
    "save_path  = data_dir\n",
    "annot_file = 'localize_classify_annotation-' + image_folder + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Localization Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a model pre-trained pre-trained on COCO\n",
    "model_localize = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes    = 2  # 1 class (person) + background\n",
    "in_features    = model_localize.roi_heads.box_predictor.cls_score.in_features\n",
    "model_localize.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "model_path  = '/home/mila/a/aditya.jain/logs/v1_localizmodel_2021-08-17-12-06.pt'\n",
    "checkpoint  = torch.load(model_path, map_location=device)\n",
    "model_localize.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelInference:\n",
    "    def __init__(self, model_path, category_map_json, device, input_size=300):\n",
    "        self.device = device\n",
    "        self.input_size = input_size\n",
    "        self.id2categ = self._load_category_map(category_map_json)\n",
    "        self.transforms = self._get_transforms()\n",
    "        self.model = self._load_model(model_path, num_classes=len(self.id2categ))\n",
    "        self.model.eval()\n",
    "\n",
    "    def _load_category_map(self, category_map_json):\n",
    "        with open(category_map_json, 'r') as f:\n",
    "            categories_map = json.load(f)\n",
    "\n",
    "        id2categ = {categories_map[categ]: categ for categ in categories_map}\n",
    "\n",
    "        return id2categ\n",
    "\n",
    "    def _get_transforms(self):\n",
    "        mean, std = [0.5, 0.5, 0.5], [0.5, 0.5, 0.5]\n",
    "\n",
    "        return transforms.Compose([\n",
    "          transforms.Resize((self.input_size, self.input_size)),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean, std),\n",
    "          ])\n",
    "\n",
    "    def _load_model(self, model_path, num_classes):\n",
    "        model = timm.create_model('tf_efficientnetv2_b3',\n",
    "                              pretrained=False,\n",
    "                              num_classes=num_classes)\n",
    "        model = model.to(self.device)\n",
    "        model.load_state_dict(torch.load(model_path,\n",
    "                                     map_location=torch.device(self.device)))\n",
    "\n",
    "        return model\n",
    "\n",
    "    def predict(self, image, confidence=False):\n",
    "        with torch.no_grad():\n",
    "            image = self.transforms(image)\n",
    "            image = image.to(self.device) \n",
    "            image = image.unsqueeze_(0)\n",
    "\n",
    "            predictions = self.model(image)\n",
    "            predictions = torch.nn.functional.softmax(predictions, dim=1)\n",
    "            predictions = predictions.cpu().numpy()\n",
    "\n",
    "            categ = predictions.argmax(axis=1)[0]\n",
    "            categ = self.id2categ[categ]\n",
    "\n",
    "            if confidence:\n",
    "                return categ, predictions.max(axis=1)[0]\n",
    "            else:\n",
    "                return categ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Binary Classification Model (moth / non-moth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(246, 250, 3)\n",
      "Prediction: nonmoth, Confidence: 0.9491909742355347\n"
     ]
    }
   ],
   "source": [
    "category_map_json = '/home/mila/a/aditya.jain/logs/05-moth-nonmoth_category_map.json'\n",
    "model_path        = '/home/mila/a/aditya.jain/logs/moth-nonmoth-effv2b3_20220506_061527_30.pth'\n",
    "   \n",
    "model_binary      = ModelInference(model_path, category_map_json, device) \n",
    "\n",
    "image = Image.open('ant.jpeg')\n",
    "print(np.shape(image))\n",
    "\n",
    "categ, conf = model_binary.predict(image, confidence=True)\n",
    "print(f'Prediction: {categ}, Confidence: {conf}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Moth Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Chlorochlamys chloroleucaria, Confidence: 0.7936117649078369\n"
     ]
    }
   ],
   "source": [
    "category_map_json = '/home/mila/a/aditya.jain/logs/03-mothsv2_category_map.json'\n",
    "model_path        = '/home/mila/a/aditya.jain/logs/mothsv2_20220421_110638_30.pth'\n",
    "   \n",
    "model_moth        = ModelInference(model_path, category_map_json, device) \n",
    "\n",
    "image = Image.open('Orthopygia_glaucinalis.jpg')\n",
    "\n",
    "categ, conf = model_moth.predict(image, confidence=True)\n",
    "print(f'Prediction: {categ}, Confidence: {conf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_localize  = model_localize.to(device)\n",
    "model_localize.eval()\n",
    "\n",
    "annot_data = {}\n",
    "SCORE_THR  = 0.99\n",
    "image_list = os.listdir(data_path)\n",
    "# image_list.sort()\n",
    "\n",
    "transform  = transforms.Compose([              \n",
    "            transforms.ToTensor()])\n",
    "\n",
    "for img in image_list:\n",
    "    image_path = data_path + img\n",
    "    raw_image  = Image.open(image_path)\n",
    "    image      = transform(raw_image)\n",
    "    image_pred = torch.unsqueeze(image, 0).to(device)\n",
    "    output     = model_localize(image_pred)\n",
    "    \n",
    "    bboxes     = output[0]['boxes'][output[0]['scores'] > SCORE_THR]  \n",
    "    \n",
    "    bbox_list     = []\n",
    "    label_list    = []\n",
    "    class_list    = []   # moth / non-moth\n",
    "    subclass_list = []   # moth species / non-moth\n",
    "    conf_list     = []   # confidence list\n",
    "    \n",
    "    for box in bboxes:\n",
    "        box_numpy = box.detach().cpu().numpy() \n",
    "        bbox_list.append([int(box_numpy[0]), int(box_numpy[1]), \\\n",
    "                          int(box_numpy[2]), int(box_numpy[3])])\n",
    "        label_list.append(1)\n",
    "        \n",
    "        cropped_image    = image[:,int(box_numpy[1]):int(box_numpy[3]), \n",
    "                                     int(box_numpy[0]):int(box_numpy[2])]\n",
    "        transform_to_PIL = transforms.ToPILImage()\n",
    "        cropped_image    = transform_to_PIL(cropped_image)\n",
    "        \n",
    "        # prediction for moth / non-moth\n",
    "        categ, conf = model_binary.predict(cropped_image, confidence=True)\n",
    "#         plt.figure()\n",
    "#         plt.imshow(np.transpose(image[:,int(box_numpy[1]):int(box_numpy[3]), \n",
    "#                                      int(box_numpy[0]):int(box_numpy[2])]))\n",
    "#         print(categ)\n",
    "        if categ == 'nonmoth':\n",
    "            class_list.append('nonmoth')\n",
    "            subclass_list.append('nonmoth')\n",
    "            conf_list.append(int(conf*100))\n",
    "        else:\n",
    "            categ, conf = model_moth.predict(cropped_image, confidence=True)\n",
    "            class_list.append('moth')\n",
    "            subclass_list.append(categ)\n",
    "            conf_list.append(int(conf*100))       \n",
    "        \n",
    "    annot_data[img] = [bbox_list, label_list, class_list, subclass_list, conf_list]\n",
    "\n",
    "with open(save_path + annot_file , 'w') as outfile:\n",
    "    json.dump(annot_data, outfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "newenv"
  },
  "kernelspec": {
   "display_name": "Python 3 (milamoth_ai)",
   "language": "python",
   "name": "milamoth_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
