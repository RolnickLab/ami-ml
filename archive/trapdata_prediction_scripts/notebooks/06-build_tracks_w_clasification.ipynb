{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Author        : Aditya Jain\n",
    "Date started  : May 22, 2022\n",
    "About         : given image sequences localization and classification info, builds the tracks\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from cost_method.iou import intersection_over_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-Defined Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = '/home/mila/a/aditya.jain/scratch/TrapData_QuebecVermont_2022/Vermont/'\n",
    "\n",
    "# cost thresholding for removing false tracks\n",
    "COST_THR  = 1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '2022_05_13'\n",
    "image_dir    = data_dir + image_folder + '/'\n",
    "annot_file   = data_dir + 'localize_classify_annotation-' + image_folder + '.json'\n",
    "track_file   = data_dir + 'track_localize_classify_annotation-' + image_folder + '.csv'\n",
    "\n",
    "data_images = os.listdir(image_dir)\n",
    "data_annot  = json.load(open(annot_file))\n",
    "\n",
    "track_info  = []    # [<image_name>, <track_id>, <bb_topleft_x>, <bb_topleft_y>, <bb_botright_x>, <bb_botright_y>\n",
    "                    #  <bb_centre_x>, <bb_centre_y>, <class>, <sub_class>, <confidence>]\n",
    "track_id    = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_track_id(image_name, annot):\n",
    "    \"\"\"finds the track id for a given image and annotation\"\"\"\n",
    "    \n",
    "    global track_info    \n",
    "    idx = -1\n",
    "    \n",
    "    while True:\n",
    "        if track_info[idx][0] == image_name:\n",
    "            if track_info[idx][2:6] == annot:\n",
    "                return track_info[idx][1]            \n",
    "        idx -= 1\n",
    "    \n",
    "    \n",
    "def save_track(data_images, data_annot, idx):\n",
    "    \"\"\"\n",
    "    finds the track between annotations of two consecutive images\n",
    "    \n",
    "    Args:\n",
    "    data_images (list) : list of trap images\n",
    "    data_annot (dict)  : dictionary containing annotation information for each image\n",
    "    idx (int)          : image index for which the track needs to be found\n",
    "    \"\"\"\n",
    "    \n",
    "    global track_info, track_id, COST_THR\n",
    "    \n",
    "    # finding the moth boxes\n",
    "    image1_annot_data = data_annot[data_images[idx-1]]\n",
    "    image1_annot      = []\n",
    "    image1_meta_data  = []\n",
    "    for i in range(len(image1_annot_data[0])):\n",
    "        if image1_annot_data[2][i]=='moth':\n",
    "            image1_annot.append(image1_annot_data[0][i])\n",
    "            image1_meta_data.append([image1_annot_data[2][i], \\\n",
    "                                     image1_annot_data[3][i], \\\n",
    "                                     image1_annot_data[4][i]])\n",
    "            \n",
    "    image2_annot_data = data_annot[data_images[idx]]\n",
    "    image2_annot      = []\n",
    "    image2_meta_data  = []\n",
    "    for i in range(len(image2_annot_data[0])):\n",
    "        if image2_annot_data[2][i]=='moth':\n",
    "            image2_annot.append(image2_annot_data[0][i])\n",
    "            image2_meta_data.append([image2_annot_data[2][i], \\\n",
    "                                     image2_annot_data[3][i], \\\n",
    "                                     image2_annot_data[4][i]])\n",
    "        else:\n",
    "            track_info.append([data_images[idx], 'NA', \n",
    "                       image2_annot_data[0][i][0], image2_annot_data[0][i][1], \n",
    "                       image2_annot_data[0][i][2], image2_annot_data[0][i][3],\n",
    "                       image2_annot_data[0][i][0] + int((image2_annot_data[0][i][2]-image2_annot_data[0][i][0])/2),\n",
    "                       image2_annot_data[0][i][1] + int((image2_annot_data[0][i][3]-image2_annot_data[0][i][1])/2),\n",
    "                       image2_annot_data[2][i], image2_annot_data[3][i], image2_annot_data[4][i]\n",
    "                       ])\n",
    "    \n",
    "    cost_matrix  = np.zeros((len(image2_annot), len(image1_annot)))\n",
    "    \n",
    "    for i in range(len(image2_annot)):\n",
    "        for j in range(len(image1_annot)):            \n",
    "            iou              = intersection_over_union(image1_annot[j], image2_annot[i])\n",
    "            cost             = 1-iou\n",
    "            cost_matrix[i,j] = cost\n",
    "            \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix) \n",
    "    \n",
    "    row_ind = list(row_ind)\n",
    "    col_ind = list(col_ind)\n",
    "    \n",
    "    for i in range(len(image2_annot)):\n",
    "        # have a previous match\n",
    "        if i in row_ind:          \n",
    "            row_idx = row_ind.index(i)\n",
    "            col_idx = col_ind[row_idx]\n",
    "            \n",
    "            # have a reasonable match from previous frame\n",
    "            if cost_matrix[i, col_idx] < COST_THR:\n",
    "                cur_id  = find_track_id(data_images[idx-1], image1_annot[col_idx])\n",
    "                track_info.append([data_images[idx], cur_id, \n",
    "                               image2_annot[i][0], image2_annot[i][1],\n",
    "                               image2_annot[i][2], image2_annot[i][3],\n",
    "                               image2_annot[i][0] + int((image2_annot[i][2]-image2_annot[i][0])/2),\n",
    "                               image2_annot[i][1] + int((image2_annot[i][3]-image2_annot[i][1])/2),\n",
    "                               image2_meta_data[i][0], image2_meta_data[i][1], image2_meta_data[i][2]])\n",
    "            \n",
    "            # the cost of matching is too high; false match; thresholding; start a new track\n",
    "            else:\n",
    "                track_info.append([data_images[idx], track_id, \n",
    "                               image2_annot[i][0], image2_annot[i][1],\n",
    "                               image2_annot[i][2], image2_annot[i][3],\n",
    "                               image2_annot[i][0] + int((image2_annot[i][2]-image2_annot[i][0])/2),\n",
    "                               image2_annot[i][1] + int((image2_annot[i][3]-image2_annot[i][1])/2),\n",
    "                               image2_meta_data[i][0], image2_meta_data[i][1], image2_meta_data[i][2]])\n",
    "                track_id += 1\n",
    "                \n",
    "        # no match, this is a new track \n",
    "        else:\n",
    "            track_info.append([data_images[idx], track_id, \n",
    "                               image2_annot[i][0], image2_annot[i][1],\n",
    "                               image2_annot[i][2], image2_annot[i][3],\n",
    "                               image2_annot[i][0] + int((image2_annot[i][2]-image2_annot[i][0])/2),\n",
    "                               image2_annot[i][1] + int((image2_annot[i][3]-image2_annot[i][1])/2),\n",
    "                               image2_meta_data[i][0], image2_meta_data[i][1], image2_meta_data[i][2]])\n",
    "            track_id += 1\n",
    "    \n",
    "    \n",
    "def draw_bounding_boxes(image, annotation):\n",
    "    \"\"\"draws bounding box annotation for a given image\"\"\"\n",
    "\n",
    "    for annot in annotation:\n",
    "        cv2.rectangle(image,(annot[0], annot[1]),(annot[2], annot[3]),(0,0,255),3)\n",
    "        \n",
    "    return image\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the tracking annotation for the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_annot      = data_annot[data_images[0]][0]\n",
    "first_annot_data = data_annot[data_images[0]]\n",
    "\n",
    "for i in range(len(first_annot)):\n",
    "    if first_annot_data[2][i]=='nonmoth':\n",
    "        track_info.append([data_images[0], 'NA', \n",
    "                       first_annot[i][0], first_annot[i][1], \n",
    "                       first_annot[i][2], first_annot[i][3],\n",
    "                       first_annot[i][0] + int((first_annot[i][2]-first_annot[i][0])/2),\n",
    "                       first_annot[i][1] + int((first_annot[i][3]-first_annot[i][1])/2),\n",
    "                       first_annot_data[2][i], first_annot_data[3][i], first_annot_data[4][i]\n",
    "                       ])\n",
    "    else:\n",
    "        track_info.append([data_images[0], track_id, \n",
    "                       first_annot[i][0], first_annot[i][1], \n",
    "                       first_annot[i][2], first_annot[i][3],\n",
    "                       first_annot[i][0] + int((first_annot[i][2]-first_annot[i][0])/2),\n",
    "                       first_annot[i][1] + int((first_annot[i][3]-first_annot[i][1])/2),\n",
    "                       first_annot_data[2][i], first_annot_data[3][i], first_annot_data[4][i]\n",
    "                       ])\n",
    "        track_id += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the tracking annotation for the rest images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(data_images)):\n",
    "    save_track(data_images, data_annot, i)\n",
    "\n",
    "track_df = pd.DataFrame(track_info, columns =['image', 'track_id', 'bb_topleft_x', \n",
    "                                              'bb_topleft_y', 'bb_botright_x', 'bb_botright_y',\n",
    "                                              'bb_centre_x', 'bb_centre_y', 'class', 'subclass', \n",
    "                                              'confidence'])\n",
    "\n",
    "track_df.to_csv(track_file, index=False)\n",
    "# track_df.to_csv('tracking_annotation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization - NOT to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img1 = cv2.imread(image_dir + data_images[i-1])\n",
    "# img2 = cv2.imread(image_dir + data_images[i])\n",
    "    \n",
    "    \n",
    "# img1 = draw_bounding_boxes(img1, data_annot[data_images[i-1]][0])\n",
    "# cv2.imwrite('image1.jpg', img1)\n",
    "# img2 = draw_bounding_boxes(img2, data_annot[data_images[i]][0])       \n",
    "# cv2.imwrite('image2.jpg', img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (milamoth_ai)",
   "language": "python",
   "name": "milamoth_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
