{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author       : Aditya Jain\n",
    "Date Started : 18th August, 2021\n",
    "About        : This file does DL-based localization by directly reading video and outputing final video\n",
    "'''\n",
    "import torch\n",
    "import torchvision.models as torchmodels\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.get(name='MothAI',\n",
    "                     subscription_id='1e5f7432-8004-48f7-a32d-668eee0f349e',\n",
    "                     resource_group='MothProject'\n",
    "                     )                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Input\n",
    "vid_name       = 'maxim_video2'\n",
    "des_fps        = 5\n",
    "frame_height   = 540\n",
    "frame_width    = 960\n",
    "home_path      = '/home/azureuser/cloudfiles/code/Users/adijain0707/data/maxim_videos/'\n",
    "\n",
    "\n",
    "final_vid_name = vid_name + '.MOV'\n",
    "video_path     = home_path + final_vid_name\n",
    "# raw_img_list   = frames_from_video(vid_path, fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# load a model pre-trained pre-trained on COCO\n",
    "model       = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "\n",
    "MODEL_PATH  = Model.get_model_path('DL_Localization_Model', _workspace=ws)\n",
    "checkpoint  = torch.load(MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Prediction and Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image(model, img):\n",
    "    SCORE_THR  = 0.98\n",
    "\n",
    "    transform  = transforms.Compose([              \n",
    "            transforms.ToTensor()])\n",
    "    \n",
    "    image      = transform(img)\n",
    "    image_pred = torch.unsqueeze(image, 0).to(device)\n",
    "    output     = model(image_pred)    \n",
    "    \n",
    "    bboxes     = output[0]['boxes'][output[0]['scores'] > SCORE_THR]\n",
    "    image_cv   = img\n",
    "    \n",
    "    for box in bboxes:\n",
    "        box_numpy = box.detach().cpu().numpy()        \n",
    "        cv2.rectangle(image_cv,(box_numpy[0], box_numpy[1]),(box_numpy[2], box_numpy[3]),(0,0,255),2)  \n",
    "        \n",
    "    return image_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap      = cv2.VideoCapture(video_path)     \n",
    "fps         = vidcap.get(cv2.CAP_PROP_FPS)           #  FPS of the video \n",
    "frame_count = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)   #  total frame count\n",
    "total_sec   = frame_count/fps\n",
    "sec         = 0\n",
    "n_frames    = total_sec*des_fps\n",
    "time_sec    = total_sec/n_frames                     # the video will be sampled after every time_sec\n",
    "    \n",
    "model       = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# initialising video writer\n",
    "out        = cv2.VideoWriter(home_path + vid_name + '_localiz.avi',\n",
    "                      cv2.VideoWriter_fourcc('M','J','P','G'), 5, (frame_width, frame_height))\n",
    "\n",
    "while sec < total_sec:        \n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)    # setting which frame to get        \n",
    "    success, image = vidcap.read()\n",
    "    if success:\n",
    "        image_annot = annotate_image(model, image)\n",
    "        out.write(image_annot)\n",
    "    \n",
    "    sec += time_sec\n",
    "    \n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "newenv"
  },
  "kernelspec": {
   "display_name": "Python 3 (milamoth)",
   "language": "python",
   "name": "milamoth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
