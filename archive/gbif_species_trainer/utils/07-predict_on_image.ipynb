{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Aditya Jain\n",
    "Date last modified  : August 24, 2023\n",
    "About : This script predicts the class given an input image\n",
    "\"\"\"\n",
    "import sys, os\n",
    "sys.path.append('/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/model_training/')\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from models.resnet50 import Resnet50\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "image_path   = 'test-moth.png'\n",
    "image_resize = 224\n",
    "config_file  = '/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/model_training/config/01-config_quebec-vermont.json' \n",
    "model_path   = '/home/mila/a/aditya.jain/logs/quebec-vermont-moth-model_v07_resnet50_2022-12-22-07-54.pt'\n",
    "label_file   = '/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/model_training/data/quebec-vermont_numeric_labels.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/utils/07-predict_on_image.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcn-f003.server.mila.quebec/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/utils/07-predict_on_image.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m config_data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcn-f003.server.mila.quebec/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/utils/07-predict_on_image.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m device      \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcn-f003.server.mila.quebec/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/utils/07-predict_on_image.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model       \u001b[39m=\u001b[39m Resnet50(config_data)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcn-f003.server.mila.quebec/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/utils/07-predict_on_image.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m checkpoint  \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(model_path, map_location\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcn-f003.server.mila.quebec/home/mila/a/aditya.jain/mothAI/gbif_species_trainer/utils/07-predict_on_image.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mmodel_state_dict\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/mothAI/gbif_species_trainer/model_training/models/resnet50.py:24\u001b[0m, in \u001b[0;36mResnet50.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackbone\u001b[39m.\u001b[39mchildren())[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m])\n\u001b[1;32m     23\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mAdaptiveAvgPool2d(output_size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m---> 24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mLinear(out_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_classes, bias\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.conda/envs/milamoth_ai/lib/python3.9/site-packages/torch/nn/modules/linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[0;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_features \u001b[39m=\u001b[39m in_features\n\u001b[1;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_features \u001b[39m=\u001b[39m out_features\n\u001b[0;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((out_features, in_features), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[1;32m     97\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[1;32m     98\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_features, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# model loading\n",
    "f           = open(config_file)\n",
    "config_data = json.load(f)\n",
    "\n",
    "device      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model       = Resnet50(config_data).to(device)\n",
    "\n",
    "checkpoint  = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image loading and processing\n",
    "image     = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                        transforms.Resize((image_resize, image_resize)),              # resize the image to 224x224 \n",
    "                        transforms.ToTensor()])\n",
    "image     = transform(image)\n",
    "image     = torch.unsqueeze(image, 0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "prediction      = model(image)\n",
    "_, predict_indx = torch.topk(prediction, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted species is :  Sphinx luscitiosa\n"
     ]
    }
   ],
   "source": [
    "f            = open(label_file)\n",
    "label_info   = json.load(f)\n",
    "species_list = label_info['species_list']\n",
    "\n",
    "print('The predicted species is : ', species_list[predict_indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sphinx luscitiosa\n",
      "Hemileuca lucina\n",
      "Proserpinus flavofasciata\n"
     ]
    }
   ],
   "source": [
    "# finding top 3 predictions\n",
    "_, predict_indx = torch.topk(prediction, 3)\n",
    "predict_indx    = predict_indx[0]\n",
    "\n",
    "for index in predict_indx:\n",
    "    print(species_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path   = 'test-moth.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image     = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milamoth_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
