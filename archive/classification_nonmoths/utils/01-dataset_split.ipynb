{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author        : Aditya Jain\n",
    "Date Started  : May 2, 2022\n",
    "About         : Division of dataset into train, validation and test sets for non-moth classifier\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "moth_data_dir    = '/home/mila/a/aditya.jain/scratch/GBIF_Data/moths/'               # root directory of moth data\n",
    "nonmoth_data_dir = '/home/mila/a/aditya.jain/scratch/GBIF_Data/nonmoths/'            # root directory of nonmoth data\n",
    "write_dir        = '/home/mila/a/aditya.jain/mothAI/classification_nonmoths/data/'   # split files to be written\n",
    "TRAIN_SPLIT      = 0.75                                                              # train set ratio\n",
    "VAL_SPLIT        = 0.10                                                              # validation set ration\n",
    "TEST_SPLIT       = 0.15                                                              # test set ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_split_list(global_pd, new_list, fields, class_name):\n",
    "    \"\"\"\n",
    "    prepares a global csv list for every type of data split\n",
    "    \n",
    "    Args:\n",
    "        global_pd: a global list into which new entries will be appended\n",
    "        new_list : list of new entries to be appended to global list   \n",
    "        fields   : contains the column names\n",
    "        class_name: moth, nonmoth\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    \n",
    "    for path in new_list:\n",
    "        path_split = path.split('/')        \n",
    "        filename   = path_split[-1]\n",
    "        \n",
    "        if class_name=='moth':\n",
    "            species    = path_split[-2]\n",
    "            genus      = path_split[-3]\n",
    "            family     = path_split[-4]\n",
    "        else:\n",
    "            species    = 'NA'\n",
    "            genus      = 'NA'\n",
    "            family     = path_split[-2]\n",
    "        \n",
    "        new_data.append([filename, family, genus, species, class_name])\n",
    "        \n",
    "    new_data  = pd.DataFrame(new_data, columns=fields)    \n",
    "    global_pd = global_pd.append(new_data, ignore_index=True)\n",
    "    \n",
    "    return global_pd        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the data split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields     = ['filename', 'family', 'genus', 'species', 'class']\n",
    "train_data = pd.DataFrame(columns = fields)\n",
    "val_data   = pd.DataFrame(columns = fields)\n",
    "test_data  = pd.DataFrame(columns = fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bifurcating the moth classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of moth training points:  207420\n"
     ]
    }
   ],
   "source": [
    "for family in os.listdir(moth_data_dir):\n",
    "    if not family.endswith('.csv') and not family.endswith('.ipynb_checkpoints'):\n",
    "        for genus in os.listdir(moth_data_dir + family):        \n",
    "            for species in os.listdir(moth_data_dir + family + '/' + genus):\n",
    "            \n",
    "                file_data  = glob.glob(moth_data_dir + family + '/' + genus + '/' + species + '/*.jpg')\n",
    "                random.shuffle(file_data)\n",
    "            \n",
    "                total      = len(file_data)\n",
    "                train_amt  = round(total*TRAIN_SPLIT)\n",
    "                val_amt    = round(total*VAL_SPLIT)            \n",
    "             \n",
    "                train_list = file_data[:train_amt]\n",
    "                val_list   = file_data[train_amt:train_amt+val_amt]\n",
    "                test_list  = file_data[train_amt+val_amt:]\n",
    "            \n",
    "                train_data = prepare_split_list(train_data, train_list, fields, 'moth')\n",
    "                val_data   = prepare_split_list(val_data, val_list, fields, 'moth')\n",
    "                test_data  = prepare_split_list(test_data, test_list, fields, 'moth')\n",
    "            \n",
    "\n",
    "moth_train_pts = len(train_data)\n",
    "print('No. of moth training points: ', moth_train_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bifurcating the nonmoth classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of non-moth training points:  158123\n"
     ]
    }
   ],
   "source": [
    "for order in os.listdir(nonmoth_data_dir):\n",
    "    if not order.endswith('.csv') and not order.endswith('.ipynb_checkpoints'):\n",
    "        \n",
    "        file_data  = glob.glob(nonmoth_data_dir + order + '/*.jpg')\n",
    "        random.shuffle(file_data)\n",
    "        \n",
    "        total      = len(file_data)\n",
    "        train_amt  = round(total*TRAIN_SPLIT)\n",
    "        val_amt    = round(total*VAL_SPLIT)            \n",
    "             \n",
    "        train_list = file_data[:train_amt]\n",
    "        val_list   = file_data[train_amt:train_amt+val_amt]\n",
    "        test_list  = file_data[train_amt+val_amt:]\n",
    "        \n",
    "        train_data = prepare_split_list(train_data, train_list, fields, 'nonmoth')\n",
    "        val_data   = prepare_split_list(val_data, val_list, fields, 'nonmoth')\n",
    "        test_data  = prepare_split_list(test_data, test_list, fields, 'nonmoth')\n",
    "        \n",
    "        \n",
    "nonmoth_train_pts = len(train_data)-moth_train_pts\n",
    "print('No. of non-moth training points: ', nonmoth_train_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of total training points:  365543\n",
      "No. of total validation points:  48736\n",
      "No. of total testing points:  73119\n"
     ]
    }
   ],
   "source": [
    "# shuffling and saving the lists to disk\n",
    "\n",
    "train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
    "val_data   = val_data.sample(frac=1).reset_index(drop=True)\n",
    "test_data  = test_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_data.to_csv(write_dir + '01-train_split.csv', index=False)\n",
    "val_data.to_csv(write_dir + '01-val_split.csv', index=False)\n",
    "test_data.to_csv(write_dir + '01-test_split.csv', index=False)\n",
    "\n",
    "print('No. of total training points: ', len(train_data))\n",
    "print('No. of total validation points: ', len(val_data))\n",
    "print('No. of total testing points: ', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365543\n",
      "365360\n"
     ]
    }
   ],
   "source": [
    "# unique entry test\n",
    "filelist = list(train_data['filename'])\n",
    "print(len(filelist))\n",
    "filelist = set(filelist)\n",
    "print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
